{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pysocialforce as psf\n",
    "import os\n",
    "import math\n",
    "import cv2\n",
    "import random\n",
    "import instances.wide_group_radius100_2ppl as instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human simulator initialization.\n",
    "Definition of Humans state, social groups and obstacles.\n",
    "Here are dfined different kind of obstacles, some of the m are real obstacles, other are fake and they will be used for labeling, mainly for ques, so a right bound and a left bound obstacles are defined, like in the paper from Andrea, this allows for automatically generating the label for the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do some resoning about the rotation/dilation cases, and hot to instantiate the simulator in this case\n",
    "def sim_init(instance):\n",
    "    #modify global variables\n",
    "    global initial_state, groups, real_obs, queue_obs, scaling_obs, obs, simulation_steps, x_dim_grid, y_dim_grid, robot_start_cont, robot_goal_cont, x_q_min, x_q_max, y_q_min, y_q_max, queue_initial_state, people_in_group, group_radius\n",
    "\n",
    "    # initial states, each entry is the position, velocity and goal of a pedestrian \n",
    "    # in the form of (px, py, vx, vy, gx, gy) Please define only positive positions\n",
    "    initial_state = instance.initial_state\n",
    "\n",
    "    people_in_group = instance.people_in_group\n",
    "    group_radius = instance.group_radius\n",
    "\n",
    "    # social groups informoation is represented as lists of indices of the state array\n",
    "    #groups = instance.groups\n",
    "    groups = [[-1]]\n",
    "\n",
    "    # list of linear obstacles given in the form of (x_min, x_max, y_min, y_max) Please define only positive coordinates\n",
    "    real_obs = instance.obs\n",
    "    queue_obs = instance.queue_obs\n",
    "    scaling_obs = instance.scaling_obs\n",
    "    if real_obs.size >0 and queue_obs.size>0:\n",
    "        print('both non empty')\n",
    "        obs = np.append(real_obs, [queue_obs, scaling_obs], axis=0)\n",
    "    elif queue_obs.size >0: \n",
    "        obs = np.append(queue_obs, scaling_obs, axis=0)\n",
    "    elif real_obs.size>0: \n",
    "        obs = np.append(real_obs, scaling_obs, axis=0)\n",
    "    else: obs = scaling_obs\n",
    "\n",
    "    \n",
    "    simulation_steps = instance.simulation_steps\n",
    "\n",
    "    x_dim_grid = instance.dim_grid\n",
    "    y_dim_grid = x_dim_grid\n",
    "\n",
    "    robot_start_cont = instance.robot_start_cont\n",
    "    robot_goal_cont = instance.robot_goal_cont\n",
    "\n",
    "    '''randomly add humans in the queue if the queue obstacle array is not empty \n",
    "        one person (randomly) every one meter segment'''\n",
    "    if queue_obs.size >0:\n",
    "        x_q_min = 25\n",
    "        x_q_max = 0\n",
    "        y_q_min = 25\n",
    "        y_q_max = 0\n",
    "        for obst in queue_obs:\n",
    "            if obst[0] < x_q_min:\n",
    "                x_q_min = obst[0]\n",
    "            if obst[1] > x_q_max:\n",
    "                x_q_max = obst[1]\n",
    "            \n",
    "            if obst[2] < y_q_min:\n",
    "                y_q_min = obst[2]\n",
    "            if obst[3] > y_q_max:\n",
    "                y_q_max = obst[3]\n",
    "\n",
    "\n",
    "        seg_factor = 1.1\n",
    "        segments = math.floor((x_q_max-x_q_min)/seg_factor)\n",
    "        \n",
    "        queue_initial_state = np.zeros((segments, 6))\n",
    "        speed_demultiplier = 0.1\n",
    "        for segment in range(segments):\n",
    "            queue_initial_state[segment, 0] = random.uniform(x_q_min+seg_factor*segment, x_q_min+seg_factor*segment+1, )\n",
    "            queue_initial_state[segment, 1] = random.uniform(y_q_min, y_q_max)\n",
    "            x_speed = speed_demultiplier*(robot_goal_cont[0] - queue_initial_state[segment, 0])/(robot_goal_cont[0] - queue_initial_state[segment, 0])**2\n",
    "            queue_initial_state[segment, 2] = x_speed + 0.1* random.uniform(-0.1 *x_speed, 0.1*x_speed)\n",
    "            y_speed = speed_demultiplier*(robot_goal_cont[1] - queue_initial_state[segment, 1])/(robot_goal_cont[1] - queue_initial_state[segment, 1])**2\n",
    "            queue_initial_state[segment, 3] = y_speed + 0.1 * random.uniform(-0.1 *y_speed, 0.1*y_speed)\n",
    "            queue_initial_state[segment, 4] = robot_goal_cont[0]\n",
    "            queue_initial_state[segment, 5] = robot_goal_cont[1]\n",
    "\n",
    "        \n",
    "\n",
    "        # append humans\n",
    "        if initial_state.size >0:\n",
    "            initial_state = np.concatenate((initial_state, queue_initial_state), axis=0)\n",
    "        \n",
    "        \n",
    "        return obs\n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_angular_distance(from_angle, to_angle):\n",
    "    # Compute the difference between the two angles\n",
    "    diff = to_angle - from_angle\n",
    "\n",
    "    # Normalize the difference to be within the range of -pi to pi\n",
    "    while diff < -math.pi:\n",
    "        diff += 2 * math.pi\n",
    "    while diff > math.pi:\n",
    "        diff -= 2 * math.pi\n",
    "\n",
    "    return diff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "place humans on gridmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def humans_in_gridmap(humans, human_gridmap):\n",
    "    # Determine the maximum x and y values for scaling\n",
    "    x_max = np.max(scaling_obs[:, 1])\n",
    "    y_max = np.max(scaling_obs[:, 3])\n",
    "\n",
    "    # Scale humans' positions to grid dimensions\n",
    "    scale_hum2grid = np.diag([x_dim_grid / x_max, y_dim_grid / y_max])\n",
    "    humans_grid_pos = np.uint16(np.floor(humans[:, :2] @ scale_hum2grid))\n",
    "\n",
    "    # Update the human_gridmap in place\n",
    "    for i in range(humans_grid_pos.shape[0]):\n",
    "        human_gridmap[humans_grid_pos[i, 0], humans_grid_pos[i, 1]] = 100\n",
    "        dx = 0\n",
    "        dy = 0\n",
    "        vx = humans[i, 2]\n",
    "        vy = humans[i, 3]\n",
    "        ratio_threshold = 2.0\n",
    "\n",
    "        # Avoid division by zero\n",
    "        if vx == 0 and vy == 0:\n",
    "            print('unknown')\n",
    "        \n",
    "        # Calculate absolute values and ratios\n",
    "        abs_vx = abs(vx)\n",
    "        abs_vy = abs(vy)\n",
    "        \n",
    "        if abs_vx > abs_vy * ratio_threshold:\n",
    "            dx = np.sign(vx)\n",
    "        elif abs_vy > abs_vx * ratio_threshold:\n",
    "            dy = np.sign(vy)\n",
    "        else:\n",
    "            dx = np.sign(vx)\n",
    "            dy = np.sign(vy)\n",
    "\n",
    "        \n",
    "        if 0 <= humans_grid_pos[i, 0] + dx < human_gridmap.shape[0] and 0 <= humans_grid_pos[i, 1] + dy < human_gridmap.shape[1]:\n",
    "            human_gridmap[int(humans_grid_pos[i,0] + dx), int(humans_grid_pos[i,1] + dy)] = max(25, human_gridmap[int(humans_grid_pos[i,0] + dx), int(humans_grid_pos[i,1] + dy)])\n",
    "            \n",
    "            #print(f'x = {human[0]} y = {human[1]}, value = {human_gridmap[human[0], human[1]]}')\n",
    "\n",
    "    return human_gridmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "place walls in map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wall_in_map(map, x0, x1, y0, y1):\n",
    "    Dx = x1 - x0\n",
    "    Dy = y1 - y0\n",
    "\n",
    "    n_of_samples = max(math.floor(max(abs(Dx), abs(Dy)) * 3000), 1)  # max to not divide by zero\n",
    "    dy = Dy / n_of_samples\n",
    "    dx = Dx / n_of_samples\n",
    "\n",
    "    for step in range(n_of_samples + 1):\n",
    "        x = math.floor(x0 + step * dx)\n",
    "        y = math.floor(y0 + step * dy)\n",
    "        # Ensure x and y are within the bounds of the map\n",
    "        if 0 <= x < map.shape[0] and 0 <= y < map.shape[1]:\n",
    "            map[x, y] = 255  # occupied\n",
    "\n",
    "    return map\n",
    "\n",
    "def walls_in_map(map, line_extremities):\n",
    "    for i in range(len(line_extremities)):\n",
    "        map = wall_in_map(map,*line_extremities[i])\n",
    "    return map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Costmap output label generation. The label shall not include the real obstacles nor their inflation layer. It should only include the overall social cost that will then be stacked on top of all the other cost layers to build the complete costmap on top of which A* will run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add queue obstacles in the label\n",
    "def queue_cost(queue_label, q_obs):\n",
    "    x_max = max(max(initial_state[:,0]), max(initial_state[:,4]), max(obs[:,1]), max(scaling_obs[:,1]))\n",
    "    y_max = max(max(initial_state[:,1]), max(initial_state[:,5]), max(obs[:,3]), max(scaling_obs[:,3]))\n",
    "    scale_obs2grid = np.diag([x_dim_grid/x_max, x_dim_grid/x_max, y_dim_grid/y_max, y_dim_grid/y_max])\n",
    "    q_grid_obs = q_obs@scale_obs2grid\n",
    "    queue_label = walls_in_map(queue_label, q_grid_obs)\n",
    "    return queue_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate group in the middle of the simulation given a group diameter and number of people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_group(radius, num_people):\n",
    "    \"\"\"\n",
    "    Samples a given number of points uniformly within a circle of a given radius.\n",
    "    \"\"\"\n",
    "    group_initial_state = [[]]\n",
    "    for i in range(num_people):\n",
    "        r = radius * np.sqrt(random.uniform(0.8, 1.2))\n",
    "        theta = random.uniform(0, 2 * np.pi)\n",
    "        x = r * np.cos(theta)\n",
    "        y = r * np.sin(theta)\n",
    "        if i == 0: \n",
    "            group_initial_state[0] = [scaling_obs[0,0]/2 + x,scaling_obs[0,2]/2 + y, -x/(x**2 + y**2)**0.5, -y/(x**2 + y**2)**0.5, 0, 0]\n",
    "        else: \n",
    "            group_initial_state.append([scaling_obs[0,0]/2 + x, scaling_obs[0,2]/2 + y, -x/(x**2 + y**2)**0.5, -y/(x**2 + y**2)**0.5, 0, 0])\n",
    "   \n",
    "    group_initial_state = np.array(group_initial_state)\n",
    "    return group_initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add groups obstacles to the label\n",
    "def group_cost(group_label, vertices):\n",
    "    \"\"\"\n",
    "    Fill the polygon defined by vertices in the given image with the value 255.\n",
    "\n",
    "    Parameters:\n",
    "    - image (np.ndarray): The input image array.\n",
    "    - vertices (np.ndarray): A numpy array of vertex coordinates.\n",
    "                             Should be of shape (n, 2) where n is the number of vertices.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: The image with the polygon filled.\n",
    "    \"\"\"\n",
    "    # Create a mask of the same size as the image, initialized to zeros\n",
    "    mask = np.zeros_like(group_label, dtype=np.uint8)\n",
    "    vertices = vertices[:, ::-1]\n",
    "    vertices = vertices.reshape((-1, 1, 2))\n",
    "\n",
    "\n",
    "    # Fill the polygon defined by vertices in the mask with 255\n",
    "    cv2.fillPoly(mask, [vertices.astype(np.int32)], color=255)\n",
    "    \n",
    "\n",
    "    # Use the mask to change the corresponding area in the original image to 255\n",
    "    group_label = np.maximum(mask, group_label)\n",
    "    #group_label = np.where(mask == 255, 255, group_label)\n",
    "    \n",
    "\n",
    "    return group_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "people costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update the costs in the costmap based on transformed people positions\n",
    "#relevant part of the cpp code is from line 271  https://github.com/robotics-upo/nav2_social_costmap_plugin/blob/humble/src/social_layer.cpp\n",
    "def people_costs(people_label, people):\n",
    "    \n",
    "    amplitude = 255.0\n",
    "    covariance_front_height = 2.0\n",
    "    covariance_front_width = 0.25\n",
    "    covariance_rear_height = 0.25\n",
    "    covariance_rear_width = 0.25\n",
    "    covariance_right_height = 0.75\n",
    "    covariance_right_width = 0.25\n",
    "    covariance_when_still = 0.25\n",
    "    use_passing = True\n",
    "    resolution = 0.4# resolution assumed to be 40 cm per square\n",
    "    tolerance_vel_still = 0.001#0.5\n",
    "    cutoff = 10\n",
    "    use_vel_factor = False\n",
    "    speed_factor = 1\n",
    "\n",
    "    # Calculate velocity magnitude and angle for each person\n",
    "    for person in people:\n",
    "        angle = np.arctan2(person[3], person[2])\n",
    "        angle_right = angle - 1.57  # 90 degrees in radians\n",
    "        cx = person[0] * resolution\n",
    "        cy = person[1] * resolution\n",
    "\n",
    "        # Iterate through each cell in the cost layer\n",
    "        for i in range(x_dim_grid):\n",
    "            for j in range(y_dim_grid):\n",
    "                x = i * resolution\n",
    "                y = j * resolution\n",
    "                mag = (person[3]**2 + person[2]**2)**0.5\n",
    "                if mag < tolerance_vel_still:\n",
    "                    # PERSON STANDS STILL\n",
    "                    a = calculate_gaussian(x, y, cx, cy, amplitude, covariance_when_still, covariance_when_still, 0)\n",
    "                else:\n",
    "                    ma = np.arctan2(y - cy, x - cx)\n",
    "                    diff = shortest_angular_distance(angle, ma)\n",
    "\n",
    "\n",
    "                    # FRONT\n",
    "                    if math.fabs(diff) < math.pi / 2:\n",
    "                        if use_vel_factor:\n",
    "                            factor = 1.0 + mag * speed_factor\n",
    "                            a = calculate_gaussian(x, y, cx, cy, amplitude, covariance_front_height * factor, covariance_front_width, angle)\n",
    "                        else:\n",
    "                            a = calculate_gaussian(x, y, cx, cy, amplitude, covariance_front_height, covariance_front_width, angle)\n",
    "                    else:  # REAR\n",
    "                        a = calculate_gaussian(x, y, cx, cy, amplitude, covariance_rear_height, covariance_rear_width, angle)\n",
    "\n",
    "                    # RIGHT SIDE\n",
    "                    if use_passing:\n",
    "                        diff_right = shortest_angular_distance(angle_right, ma)\n",
    "                        if math.fabs(diff_right) < math.pi / 2:\n",
    "                            a_right = calculate_gaussian(x, y, cx, cy, amplitude, covariance_right_height, covariance_right_width, angle_right)\n",
    "                            a = max(a, a_right)\n",
    "                    \n",
    "                    \n",
    "\n",
    "                if a < cutoff:\n",
    "                    continue\n",
    "\n",
    "                # Update the cost in the costmap\n",
    "                old_cost = people_label[i, j]\n",
    "                people_label[i, j] = max(a, old_cost)\n",
    "                \n",
    "    return people_label\n",
    "\n",
    "\n",
    "# Function to calculate Gaussian value\n",
    "def calculate_gaussian(x, y, x0, y0, A, varx, vary, skew):\n",
    "    dx = x - x0\n",
    "    dy = y - y0\n",
    "    h = np.sqrt(dx ** 2 + dy ** 2)\n",
    "    angle = np.arctan2(dy, dx)\n",
    "    mx = np.cos(angle - skew) * h\n",
    "    my = np.sin(angle - skew) * h\n",
    "    f1 = mx ** 2 / (2 * varx)\n",
    "    f2 = my ** 2 / (2 * vary)\n",
    "    return A * np.exp(-(f1 + f2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rotate numpy vectors, the first two elements are rotated around (8,8), that's the center of the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_vector(angle, vector):\n",
    "    \"\"\"\n",
    "    Rotates the elements of the input vector around specified points.\n",
    "    \n",
    "    Parameters:\n",
    "        angle (float): The angle by which to rotate the vector elements (in radians).\n",
    "        vector (numpy array): A 1D numpy array with either 2, 4, or 6 elements.\n",
    "        \n",
    "    Returns:\n",
    "        numpy array: The rotated vector.\n",
    "    \"\"\"\n",
    "    if vector.size not in [2, 4, 6]:\n",
    "        raise ValueError(f\"Vector must have either 2, 4, or 6 elements.\\nInstead it has {vector.size} elements\")\n",
    "    \n",
    "    centers = [(8, 8), (0, 0), (8, 8)]\n",
    "    cos_angle = np.cos(angle)\n",
    "    sin_angle = np.sin(angle)\n",
    "    \n",
    "    rotated_vector = np.zeros_like(vector)\n",
    "    \n",
    "    for i in range(0, vector.size, 2):\n",
    "        x, y = vector[i], vector[i+1]\n",
    "        center = centers[i // 2]\n",
    "        \n",
    "        # Translate point to origin\n",
    "        x_translated = x - center[0]\n",
    "        y_translated = y - center[1]\n",
    "        \n",
    "        # Rotate point\n",
    "        x_rotated = x_translated * cos_angle - y_translated * sin_angle\n",
    "        y_rotated = x_translated * sin_angle + y_translated * cos_angle\n",
    "        \n",
    "        # Translate point back\n",
    "        rotated_vector[i] = x_rotated + center[0]\n",
    "        rotated_vector[i+1] = y_rotated + center[1]\n",
    "    \n",
    "    return rotated_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the gridmap that will be input for the neural network is obtained. Only the real obstacles are taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gridmap_input(social_input, version):\n",
    "    x_max = max(scaling_obs[:,1])\n",
    "    y_max = max(scaling_obs[:,3])\n",
    "\n",
    "\n",
    "    #define map and add obstacles\n",
    "    #y_dim_grid = math.ceil(y_max/x_max *x_dim_grid)\n",
    "    #grid_obs = np.empty((len(obs),2))\n",
    "    #grid_obs\n",
    "    # rescale obstacles coordinate for grid\n",
    "    scale_obs2grid = np.diag([x_dim_grid/x_max, x_dim_grid/x_max, y_dim_grid/y_max, y_dim_grid/y_max])\n",
    "    gridmap = np.zeros((x_dim_grid,y_dim_grid), dtype=np.uint8) # rows-> y\n",
    "\n",
    "    # don't consider the queue obstacles, just the real ones\n",
    "    if real_obs.size >0:\n",
    "        grid_obs = real_obs@scale_obs2grid\n",
    "        gridmap = walls_in_map(gridmap,grid_obs)\n",
    "    gridmap = np.maximum(gridmap, social_input)\n",
    "\n",
    "    #rescale robot start and goal to grid\n",
    "    scale_robot2grid = np.diag([x_dim_grid/x_max,  y_dim_grid/y_max])\n",
    "    robot_goal = tuple(np.uint8(np.floor(robot_goal_cont@scale_robot2grid)))\n",
    "    \n",
    "    map = instance.__file__.split(\"/\")[-1].split(\".\")[0]\n",
    "    parent_dir = os.path.abspath(os.getcwd())\n",
    "    output_dir = os.path.join(parent_dir, 'images/in_out')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cv2.imwrite(os.path.join(output_dir, f'{map}_step_{version}_in.jpg'), gridmap)\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the label is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_costmap_output(social_cost_layer, version):\n",
    "    map = instance.__file__.split(\"/\")[-1].split(\".\")[0]\n",
    "    parent_dir = os.path.abspath(os.getcwd())\n",
    "    output_dir = os.path.join(parent_dir, 'images/in_out')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cv2.imwrite(os.path.join(output_dir, f'{map}_step_{version}_out.jpg'), social_cost_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create samples from all the instances available. Also apply rotations to the instances before feeding them into the input and output generation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 0\n",
    "\n",
    "#10 for queue, 100 for all groups, 0 for single person -> plus group script if generating person\n",
    "for i in range(100):\n",
    "    # instantiate all the necessary variables for the simulator\n",
    "    obs = sim_init(instance)\n",
    "\n",
    "    \n",
    "    if people_in_group >0:\n",
    "        additional_group = []\n",
    "        group_initial_state = generate_group(group_radius, people_in_group)\n",
    "        \n",
    "        for i in range(people_in_group):\n",
    "            additional_group.append(i)\n",
    "        #print(additional_group)\n",
    "        groups.append(additional_group)\n",
    "        if initial_state.size >0:\n",
    "            initial_state = np.append(group_initial_state, initial_state, axis=0)\n",
    "        else: initial_state = group_initial_state\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # initiate the simulator\n",
    "    s = psf.Simulator(\n",
    "        initial_state,\n",
    "        groups=groups,\n",
    "        obstacles=obs, # don't instantiate queue obstacles in the sim\n",
    "        config_file=\"/home/filippo-aisa/Projects/SocialEncDec/src/PySocialForce/examples/example.toml\",\n",
    "    )\n",
    "    \n",
    "\n",
    "    x_max =  max(scaling_obs[:,1])\n",
    "    y_max = max(scaling_obs[:,3])\n",
    "\n",
    "\n",
    "    queue_input =  np.zeros((x_dim_grid,y_dim_grid), dtype=np.uint8)\n",
    "    queue_label = np.zeros((x_dim_grid,y_dim_grid), dtype=np.uint8)\n",
    "    group_input =  np.zeros((x_dim_grid,y_dim_grid), dtype=np.uint8)\n",
    "    group_label = np.zeros((x_dim_grid,y_dim_grid), dtype=np.uint8)\n",
    "    non_group_input =  np.zeros((x_dim_grid,y_dim_grid), dtype=np.uint8)\n",
    "    non_group_label = np.zeros((x_dim_grid,y_dim_grid), dtype=np.uint8)\n",
    "    people_input = np.zeros((x_dim_grid,y_dim_grid), dtype=np.uint8)\n",
    "    people_label = np.zeros((x_dim_grid,y_dim_grid), dtype=np.uint8)\n",
    "    scale_hum2grid = np.diag([x_dim_grid/x_max,  y_dim_grid/y_max])\n",
    "\n",
    "    lonely_humans = initial_state\n",
    "    \n",
    "\n",
    "    if queue_obs.size >0:\n",
    "        q_on_grid = np.concatenate([queue_initial_state[:,:2]@scale_hum2grid, queue_initial_state[:,2:4]], axis=1)\n",
    "        \n",
    "        queue_input = humans_in_gridmap(queue_initial_state, queue_input)\n",
    "        queue_input[int(np.floor(robot_goal_cont[0]*scale_hum2grid[0,0])), int(np.floor(robot_goal_cont[1]*scale_hum2grid[1,1]))] = 200\n",
    "        \n",
    "        # we don't add the people in the cost because we want A* to converge fast\n",
    "        queue_label = queue_cost(queue_label, queue_obs)\n",
    "\n",
    "        save_costmap_output(queue_label, version)\n",
    "        save_gridmap_input(queue_input, version)\n",
    "        version = version + 1\n",
    "        save_costmap_output(queue_label.T, version)\n",
    "        save_gridmap_input(queue_input.T, version)\n",
    "        version = version + 1\n",
    "        \n",
    "        rotation_angles = np.random.uniform(0, 360, (30))\n",
    "        for angle in rotation_angles:\n",
    "            rotated_queue_input =  np.zeros((x_dim_grid,y_dim_grid), dtype=np.uint8)\n",
    "            rotated_queue_label = np.zeros((x_dim_grid,y_dim_grid), dtype=np.uint8)\n",
    "            rotated_q_initial_state = np.zeros_like(queue_initial_state)\n",
    "            rotated_robot_goal = rotate_vector(angle, np.array(robot_goal_cont))\n",
    "            for i in range(queue_initial_state.shape[0]):\n",
    "                rotated_q_initial_state[i,:] = rotate_vector(angle, queue_initial_state[i,:])\n",
    "                x_speed = rotated_robot_goal[0] - rotated_q_initial_state[i,0]\n",
    "                y_speed = rotated_robot_goal[1] - rotated_q_initial_state[i,1]\n",
    "                \n",
    "                rotated_q_initial_state[i,2] = 0.1* x_speed + 0.1*random.uniform(-0.1 *x_speed, 0.1*x_speed)\n",
    "                rotated_q_initial_state[i,3] = 0.1* y_speed + 0.1*random.uniform(-0.1 *y_speed, 0.1*y_speed)\n",
    "            \n",
    "            rotated_queue_input[int(np.floor(rotated_robot_goal[0]*scale_hum2grid[0,0])), int(np.floor(rotated_robot_goal[1]*scale_hum2grid[1,1]))] = 200\n",
    "            q_on_grid = np.concatenate([rotated_q_initial_state[:,:2]@scale_hum2grid, rotated_q_initial_state[:,2:4]], axis=1)\n",
    "            \n",
    "            rotated_queue_input = humans_in_gridmap(rotated_q_initial_state, rotated_queue_input)\n",
    "            \n",
    "            rotated_q_obs = np.zeros_like(queue_obs)\n",
    "            for i in range(queue_obs.shape[0]):\n",
    "                rotated_q_obs[i,0:3:2] = rotate_vector(angle, queue_obs[i,0:3:2])\n",
    "                rotated_q_obs[i,1::2] = rotate_vector(angle, queue_obs[i,1::2])\n",
    "            # we don't add the people in the cost because we want A* to converge fast\n",
    "            rotated_queue_label = queue_cost(rotated_queue_label, rotated_q_obs)\n",
    "\n",
    "\n",
    "\n",
    "            save_costmap_output(rotated_queue_label, version)\n",
    "            save_gridmap_input(rotated_queue_input, version)\n",
    "            version = version + 1\n",
    "\n",
    "\n",
    "\n",
    "    if len(groups) >0:\n",
    "        for group in groups:\n",
    "            if len(group) > 1:\n",
    "                vertices = np.floor(initial_state[group,:2]@scale_hum2grid).astype(np.int32)\n",
    "                group_label = group_cost(group_label, vertices)\n",
    "                group_label = people_costs(group_label, np.concatenate([initial_state[group,:2]@scale_hum2grid, initial_state[group,2:4]], axis=1))\n",
    "                group_input = humans_in_gridmap(initial_state[group],group_input)\n",
    "\n",
    "                # if people are not facing the center of the group, then the group cost is not used, only the cost associated with the people is considered\n",
    "                non_group_input = humans_in_gridmap(np.concatenate([initial_state[group,:2], initial_state[group,:2] - 8*np.ones_like(initial_state[group,:2])], axis=1),non_group_input)\n",
    "                non_group_label = people_costs(non_group_label, np.concatenate([initial_state[group,:2]@scale_hum2grid, initial_state[group,:2] - 8*np.ones_like(initial_state[group,:2])], axis=1))\n",
    "                map = instance.__file__.split(\"/\")[-1].split(\".\")[0]\n",
    "                parent_dir = os.path.abspath(os.getcwd())\n",
    "                output_dir = os.path.join(parent_dir, 'images/in_out')\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                cv2.imwrite(os.path.join(output_dir,f'non_{map}_step_{version}_out.jpg'), non_group_label)\n",
    "                cv2.imwrite(os.path.join(output_dir,f'non_{map}_step_{version}_in.jpg'), non_group_input)\n",
    "                \n",
    "            \n",
    "        \n",
    "        people_in_group_indeces = [person for group in groups for person in group]\n",
    "        mask = np.zeros(len(lonely_humans), dtype=bool)\n",
    "        mask[people_in_group_indeces] = False\n",
    "        lonely_humans = lonely_humans[mask]\n",
    "    \n",
    "    if lonely_humans.size >0:\n",
    "        pass\n",
    "        #TODO: here we are also considering the people in queue but we should not, \n",
    "        # also it seems like we are somehow seeing the robot start as a person\n",
    "        #humans_in_gridmap(lonely_humans, people_input)\n",
    "        #people_label = people_costs(people_label, lonely_humans)\n",
    "\n",
    "    \n",
    "    social_cost_layer = np.maximum(group_label, np.maximum(queue_label, people_label))\n",
    "    social_input = np.maximum(queue_input, np.maximum(group_input, people_input))\n",
    "    \n",
    "    save_costmap_output(social_cost_layer, version)\n",
    "    save_gridmap_input(social_input, version)\n",
    "    version = version + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create single human instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" version = 0\\nfor i in range(1000):\\n    x = random.uniform(0.0, 16.0)\\n    y = random.uniform(0.0, 16.0)\\n    vx = random.uniform(-1,1)\\n    vy = random.uniform(-1,1)\\n    person = np.array([[x,y,vx,vy]])\\n    person_input =  np.zeros((x_dim_grid,y_dim_grid), dtype=np.uint8)\\n    person_label = np.zeros((x_dim_grid,y_dim_grid), dtype=np.uint8)\\n    person_input = humans_in_gridmap(person,person_input)\\n    person_label = people_costs(person_label, np.concatenate([person[:,:2]@scale_hum2grid, person[:,2:4]], axis=1))\\n    parent_dir = os.path.abspath(os.getcwd())\\n    output_dir = os.path.join(parent_dir, 'images/in_out')\\n    os.makedirs(output_dir, exist_ok=True)\\n    cv2.imwrite(os.path.join(output_dir, f'single_person_step_{version}_out.jpg'), person_label)\\n    cv2.imwrite(os.path.join(output_dir, f'single_person_step_{version}_in.jpg'), person_input)\\n    version = version+1 \""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" version = 0\n",
    "for i in range(1000):\n",
    "    x = random.uniform(0.0, 16.0)\n",
    "    y = random.uniform(0.0, 16.0)\n",
    "    vx = random.uniform(-1,1)\n",
    "    vy = random.uniform(-1,1)\n",
    "    person = np.array([[x,y,vx,vy]])\n",
    "    person_input =  np.zeros((x_dim_grid,y_dim_grid), dtype=np.uint8)\n",
    "    person_label = np.zeros((x_dim_grid,y_dim_grid), dtype=np.uint8)\n",
    "    person_input = humans_in_gridmap(person,person_input)\n",
    "    person_label = people_costs(person_label, np.concatenate([person[:,:2]@scale_hum2grid, person[:,2:4]], axis=1))\n",
    "    parent_dir = os.path.abspath(os.getcwd())\n",
    "    output_dir = os.path.join(parent_dir, 'images/in_out')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cv2.imwrite(os.path.join(output_dir, f'single_person_step_{version}_out.jpg'), person_label)\n",
    "    cv2.imwrite(os.path.join(output_dir, f'single_person_step_{version}_in.jpg'), person_input)\n",
    "    version = version+1 \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
